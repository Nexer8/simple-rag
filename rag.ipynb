{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7984008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma as ChromaVectorStore\n",
    "from langchain_chroma import Chroma as ChromaLoader\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01b0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options: snowflake-arctic-embed2, nomic-embed-text\n",
    "OLLAMA_EMBEDDINGS_MODEL = \"snowflake-arctic-embed2\"\n",
    "# Options: zephyr:7b-beta\n",
    "OLLAMA_LLM_MODEL = \"llama3.2:1b\"\n",
    "# Options: BAAI/bge-reranker-large, BAAI/bge-reranker-base\n",
    "HF_RERANKER = \"BAAI/bge-reranker-large\"\n",
    "\n",
    "QA_PROMPT_TEMPLATE = (\n",
    "    \"You are a technical assistant for u-blox.\\n\"\n",
    "    \"Answer the question using only the provided context.\\n\"\n",
    "    \"- If the answer is not explicitly contained in the context, respond only with: \"\n",
    "    '\"The document does not specify.\" Do not add anything else.\\n'\n",
    "    \"- Provide concise, technical answers. Use bullet points for lists.\\n\"\n",
    "    \"- If the context contains conflicting information, state that clearly without guessing.\\n\\n\"\n",
    "    \"Question: {question}\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b637a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"data/InterfaceDescription.pdf\"\n",
    "docs = PyMuPDFLoader(doc_path).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaecd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=250)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1626fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = \"chroma_store\"\n",
    "collection_name = \"ubx_docs\"\n",
    "embeddings_model = OllamaEmbeddings(model=OLLAMA_EMBEDDINGS_MODEL)\n",
    "\n",
    "if os.path.exists(persist_dir) and os.listdir(persist_dir):\n",
    "    vectorstore = ChromaLoader(\n",
    "        persist_directory=persist_dir,\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings_model,\n",
    "    )\n",
    "else:\n",
    "    vectorstore = ChromaVectorStore.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings_model,\n",
    "        persist_directory=persist_dir,\n",
    "        collection_name=collection_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd535cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "keyword_retriever = BM25Retriever.from_documents(chunks, kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337ae1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OllamaLLM(model=OLLAMA_LLM_MODEL, temperature=0.2),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ContextualCompressionRetriever(\n",
    "        base_compressor=CrossEncoderReranker(\n",
    "            model=HuggingFaceCrossEncoder(model_name=HF_RERANKER), top_n=5\n",
    "        ),\n",
    "        base_retriever=EnsembleRetriever(\n",
    "            retrievers=[vectorstore_retriever, keyword_retriever], weights=[0.3, 0.7]\n",
    "        ),\n",
    "        search_kwargs={\"score_threshold\": 0.2},\n",
    "        chain_type_kwargs={\"prompt\": PromptTemplate.from_template(QA_PROMPT_TEMPLATE)},\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0fe8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine which UBX message to use to get satellites in view, you should look for a message that contains information about the GNSS (Global Navigation Satellite System) satellites. \n",
      "\n",
      "The NMEA-Standard-GGA is mentioned in the context of getting global positioning fix data, but it does not provide information about satellite constellations.\n",
      "\n",
      "On the other hand, the UBX-NAV-SIG message is specifically designed to report on signal identifications and constellation information for a given set of GNSS satellites. This message can be used to get information about the satellites in view, including their IDs and constellations.\n",
      "\n",
      "Therefore, you should use the UBX-NAV-SIG message to get satellites in view.\n"
     ]
    }
   ],
   "source": [
    "response = hybrid_chain.invoke(\n",
    "    \"Which UBX message to use to get satellites in view? I need their IDs and constellations.\"\n",
    ")\n",
    "print(response[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
